# Discord Bot Token
DISCORD_TOKEN=

# AI Backend Configuration
# Backend for text generation ('openai' or 'ollama')
TEXT_BACKEND=openai

# --- OpenAI/OpenRouter Configuration ---
OPENAI_API_KEY=
OPENAI_API_BASE=https://openrouter.ai/api/v1
OPENAI_TEXT_MODEL=qwen/qwen3-235b-a22b:free
VL_MODEL=qwen/qwen2.5-vl-72b-instruct:free

# --- Ollama Configuration ---
OLLAMA_BASE_URL=http://localhost:11434
TEXT_MODEL=qwen3-235b-a22b

# --- Screenshot API Configuration ---
# Get a key from https://screenshotmachine.com
SCREENSHOT_API_KEY=your_screenshot_api_key_here
SCREENSHOT_API_URL=https://api.screenshotmachine.com
SCREENSHOT_API_DEVICE=desktop
SCREENSHOT_API_DIMENSION=1024x768
SCREENSHOT_API_FORMAT=jpg
SCREENSHOT_API_CACHE_LIMIT=2
SCREENSHOT_API_TIMEOUT=5000
SCREENSHOT_API_DELAY=2000
SCREENSHOT_API_COOKIES=
SCREENSHOT_API_CLICK=

# --- Bot Settings ---
TEMPERATURE=0.7
TIMEOUT=120.0
CHANGE_NICKNAME=True
MAX_CONVERSATION_LENGTH=50
MAX_USER_MEMORY=1000
MEMORY_SAVE_INTERVAL=30

# --- Context Management ---
CONTEXT_FILE_PATH=context.json
MAX_CONTEXT_MESSAGES=10
# Set to 'true' to disable all file-based context and run in a fully ephemeral mode
IN_MEMORY_CONTEXT_ONLY=false

# --- Prompt Files ---
# Optional: Set a custom path for the prompts file
PROMPT_FILE=prompts/prompt-pry-super-chill-v2.txt
VL_PROMPT_FILE=prompts/prompt-see-v1.txt

# --- Prometheus Metrics Configuration ---
# Enable Prometheus metrics collection and HTTP server
PROMETHEUS_ENABLED=true
# Port for Prometheus metrics HTTP server (set to 0 to auto-select available port)
PROMETHEUS_PORT=8000
# Enable HTTP server for metrics scraping (set to false for metrics without HTTP endpoint)
PROMETHEUS_HTTP_SERVER=true
