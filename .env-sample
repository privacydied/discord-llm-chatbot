# Discord Bot Token
DISCORD_TOKEN=

# AI Backend Configuration
# Backend for text generation ('openai' or 'ollama')
TEXT_BACKEND=openai

# --- OpenAI/OpenRouter Configuration ---
OPENAI_API_KEY=
OPENAI_API_BASE=https://openrouter.ai/api/v1
OPENAI_TEXT_MODEL=qwen/qwen3-235b-a22b:free
VL_MODEL=qwen/qwen2.5-vl-72b-instruct:free

# --- Ollama Configuration ---
OLLAMA_BASE_URL=http://localhost:11434
TEXT_MODEL=qwen3-235b-a22b

# --- Screenshot API Configuration ---
# Get a key from https://screenshotmachine.com
SCREENSHOT_API_KEY=your_screenshot_api_key_here
SCREENSHOT_API_URL=https://api.screenshotmachine.com
SCREENSHOT_API_DEVICE=desktop
SCREENSHOT_API_DIMENSION=1024x768
SCREENSHOT_API_FORMAT=jpg
SCREENSHOT_API_DELAY=2000
SCREENSHOT_API_COOKIES=

# --- Bot Settings ---
TEMPERATURE=0.7
TIMEOUT=120.0
CHANGE_NICKNAME=True
MAX_CONVERSATION_LENGTH=50
MAX_USER_MEMORY=1000
MEMORY_SAVE_INTERVAL=30

# --- Context Management ---
CONTEXT_FILE_PATH=context.json
MAX_CONTEXT_MESSAGES=10
# Set to 'true' to disable all file-based context and run in a fully ephemeral mode
IN_MEMORY_CONTEXT_ONLY=false

# --- Prompt Files ---
# Optional: Set a custom path for the prompts file
PROMPT_FILE=prompts/prompt-pry-super-chill-v2.txt
VL_PROMPT_FILE=prompts/prompt-see-v1.txt

# --- Prometheus Metrics Configuration ---
# Enable Prometheus metrics collection and HTTP server
PROMETHEUS_ENABLED=true
# Port for Prometheus metrics HTTP server (set to 0 to auto-select available port)
PROMETHEUS_PORT=8000
# Enable HTTP server for metrics scraping (set to false for metrics without HTTP endpoint)
PROMETHEUS_HTTP_SERVER=true

# --- Online Search (DDG default, pluggable) ---
SEARCH_PROVIDER=ddg
SEARCH_MAX_RESULTS=5
SEARCH_SAFE=moderate
SEARCH_LOCALE=
DDG_API_ENDPOINT=https://duckduckgo.com/html/
# Set to true to force legacy HTML endpoint (bypasses ddgs client)
DDG_FORCE_HTML=true
# Optionally target the HTML mirror endpoint
# DDG_API_ENDPOINT=https://html.duckduckgo.com/html/
DDG_API_KEY=
DDG_TIMEOUT_MS=5000
CUSTOM_SEARCH_API_ENDPOINT=
CUSTOM_SEARCH_API_KEY=
CUSTOM_SEARCH_HEADERS=
CUSTOM_SEARCH_TIMEOUT_MS=8000
CUSTOM_SEARCH_RESULT_PATHS=
SEARCH_POOL_MAX_CONNECTIONS=10
SEARCH_BREAKER_FAILURE_WINDOW=5
SEARCH_BREAKER_OPEN_MS=15000
SEARCH_BREAKER_HALFOPEN_PROB=0.25
SEARCH_INLINE_MAX_CONCURRENCY=3

# --- Screenshot API (for !ss) ---
# Configure external screenshot provider
SCREENSHOT_API_KEY=
SCREENSHOT_API_URL=https://api.screenshotmachine.com
SCREENSHOT_API_DEVICE=desktop
SCREENSHOT_API_DIMENSION=1280x1024
SCREENSHOT_API_FORMAT=png
SCREENSHOT_API_DELAY=2000
# Optional: pass cookie string if provider/site requires consent/auth (use with care)
SCREENSHOT_API_COOKIES=

# Local fallback using Playwright (if API missing/fails)
SCREENSHOT_FALLBACK_PLAYWRIGHT=true
SCREENSHOT_PW_VIEWPORT=1280x1024
SCREENSHOT_PW_TIMEOUT_MS=15000
# Optional: override user agent for sites with UA gating
SCREENSHOT_PW_USER_AGENT=

# --- Twitter/X API (API-first) ---
# Feature flag: enable API-first integration for Twitter/X
X_API_ENABLED=false

# Auth mode and token (OAuth2 app-only bearer). NEVER commit real tokens.
X_API_AUTH_MODE=oauth2_app
X_API_BEARER_TOKEN=

# Fallback policy (scrape only on allowed conditions)
# If true, require API for Twitter and do NOT scrape on 401/403/404/410
X_API_REQUIRE_API_FOR_TWITTER=false
# Allow fallback on 5xx/timeouts only (respects Retry-After on 429)
X_API_ALLOW_FALLBACK_ON_5XX=true

# Syndication (bearerless) JSON tier for tweets
X_SYNDICATION_ENABLED=true

# Route tweet photos to vision-language analysis (VL)
X_API_ROUTE_PHOTOS_TO_VL=true

# Networking / resilience
X_API_TIMEOUT_MS=8000
X_API_RETRY_MAX_ATTEMPTS=5
X_API_BREAKER_FAILURE_WINDOW=5
X_API_BREAKER_OPEN_MS=15000
X_API_BREAKER_HALFOPEN_PROB=0.25

# Field hydration (comma-separated lists)
X_TWEET_FIELDS=id,text,created_at,author_id,public_metrics,possibly_sensitive,lang,attachments,entities,referenced_tweets,conversation_id
X_EXPANSIONS=author_id,attachments.media_keys,referenced_tweets.id,referenced_tweets.id.author_id
X_MEDIA_FIELDS=media_key,type,url,preview_image_url,variants,width,height,alt_text,public_metrics
X_USER_FIELDS=id,name,username,profile_image_url,verified,protected
X_POLL_FIELDS=id,options,duration_minutes,end_datetime,voting_status
X_PLACE_FIELDS=full_name,id,country_code,geo,name,place_type

# Routing default for Twitter
TWITTER_ROUTE_DEFAULT=api_first

# --- Streaming Status Cards ---
STREAMING_ENABLE=false
STREAMING_EMBED_STYLE=compact
STREAMING_TICK_MS=750
STREAMING_MAX_STEPS=8

# ===== ROUTER SPEED OPTIMIZATION CONFIGURATION =====

# --- Router & Concurrency ---
# Enable fast classification with compiled regex tables for zero-I/O planning
ROUTER_FAST_CLASSIFY_ENABLE=true
# Max concurrency for light operations (planning/parsing)
ROUTER_MAX_CONCURRENCY_LIGHT=8
# Max concurrency for network operations (HTTP requests)
ROUTER_MAX_CONCURRENCY_NETWORK=32
# Max concurrency for heavy operations (OCR/STT/ffmpeg)
ROUTER_MAX_CONCURRENCY_HEAVY=2
# Minimum milliseconds between Discord message edits (coalescing)
EDIT_COALESCE_MIN_MS=700

# --- HTTP Client Optimization ---
# Enable HTTP/2 support where safe
HTTP2_ENABLE=true
# DNS cache TTL in seconds
HTTP_DNS_CACHE_TTL_S=300
# Maximum total HTTP connections in pool
HTTP_MAX_CONNECTIONS=64
# Maximum keep-alive connections to reuse
HTTP_MAX_KEEPALIVE_CONNECTIONS=32
# Connection establishment timeout in milliseconds
HTTP_CONNECT_TIMEOUT_MS=1500
# Per-request read timeout in milliseconds
HTTP_READ_TIMEOUT_MS=5000
# Total request deadline in milliseconds
HTTP_TOTAL_DEADLINE_MS=6000

# --- Tweet Flow Optimization ---
# Enable tweet-specific flow (Cache → Syndication → Web → API-last)
TWEET_FLOW_ENABLED=true
# Syndication JSON endpoint total deadline in milliseconds
TWEET_SYNDICATION_TOTAL_DEADLINE_MS=3500
# Web extraction tier A timeout (lightweight HTTPX)
TWEET_WEB_TIER_A_MS=2500
# Web extraction tier B timeout (Playwright with network-JSON)
TWEET_WEB_TIER_B_MS=8000
# Web extraction tier C timeout (Selenium fallback)
TWEET_WEB_TIER_C_MS=8000
# X API total deadline (last resort only if enabled)
X_API_TOTAL_DEADLINE_MS=6000
# Tweet text/photo cache TTL in seconds (24 hours)
TWEET_CACHE_TTL_S=86400
# Negative cache TTL for 403/404 errors in seconds (15 minutes)
TWEET_NEGATIVE_TTL_S=900

# --- STT Optimization ---
# Enable speech-to-text processing
STT_ENABLE=true
# STT execution mode: parallel_first_acceptable for speed
STT_MODE=parallel_first_acceptable
# Maximum concurrent STT providers
STT_GLOBAL_MAX_CONCURRENCY=3
# Total STT processing deadline in milliseconds (5 minutes)
STT_TOTAL_DEADLINE_MS=300000
# STT result cache TTL in seconds (7 days)
STT_CACHE_TTL_S=604800

# --- General URL Processing ---
# Web extraction tier A timeout (static HTML readability)
WEB_TIER_A_MS=2000
# Web extraction tier B timeout (Playwright with network-JSON)
WEB_TIER_B_MS=8000
# Web extraction tier C timeout (Selenium fallback)
WEB_TIER_C_MS=8000
# Known SPA/WAF hosts to skip tier A (comma-separated)
WEB_FAST_FAIL_SPA_HOSTS=medium.com,heavy.com

# --- OCR Processing ---
# Global OCR processing deadline in milliseconds (4 minutes)
OCR_GLOBAL_DEADLINE_MS=240000
# Per-batch OCR deadline in milliseconds
OCR_BATCH_DEADLINE_MS=20000

# --- Caching & Single-Flight ---
# Enable single-flight deduplication for concurrent identical requests
CACHE_SINGLE_FLIGHT_ENABLE=true
# Readability extraction cache TTL in seconds (4 hours)
CACHE_READABILITY_TTL_S=14400
# Cache backend: memory, redis, or disk
CACHE_BACKEND=memory
# Cache directory for disk backend
CACHE_DIR=.cache/router
